{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "7ef2494915810854adb4ba9dd9b422179b2b7400815761b542ae58f14c894363"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Developing retropsective causal inference\n",
    "\n",
    "A retrospective model uses data including entities with and without an effect condition. Entities with the effect condition are then matched to those without it. Finally, differences in the frequency of the potential causal factors are investigated for correlation with the effect condition. Because we carefully construct the similar, non-effect group to match the effect group, we control for a wide range cofactors. This is not perfect (see \"Disadvantages\" below), but it's a powerful way to survey a wide range of potential causal factors for an effect.\n",
    "\n",
    "## Benefits of Causal inference\n",
    "\n",
    "Causal inferences allow us to influence outcomes. We don't just want to predict how long we will live, how well kids will do in school, or which patients will die of a heart attack: we want to increase our life spans, help kids learn, and prevent needless deaths. Hence, we need to know not only which variables _predict_ but also which variables _cause_ outcomes. \n",
    "\n",
    "\n",
    "## Example: Pitcher Injury\n",
    "\n",
    "Baseball teams often can't do injury experiments on their players. Practically, they need their pitchers to pitch their best, not pitch in a way that investigates the effect of pitching differently. Ethically, they can't expose their pitchers to risky treatments. Legally, the CBA wouldn't allow it. This is an ideal situation for retrospective analysis. But baseball teams and players want to reduce player injuries, so they need to figure out which factors influence injury risk.\n",
    "\n",
    "Among the varibales that a team can control are workloads, how often and how much he pitches. Does workload influence injury? A retrospective analysis might provide an answer.\n",
    "\n",
    "**Step one:** we identify pitchers who have a particular serious injury, such as a UCL tear requiring ligament replacement. \n",
    "\n",
    "**Step two:** we idenfity pitchers who did not have that injury. For each pitcher in the the group with the injury (the effect group), we identify a similar pitcher in the uninjured group. Similarity can be determined with many factors, as long as we don't include the factors that we want to analyze for an causal influence; initially, we might use age, weight, height, BMI, team affiliation, velocity, and prior injury history.\n",
    "\n",
    "**Step three:** we examine any features that we didn't use to determine similarity. Any feature that is more common in the injured group is a candidate causal factor; i.e., this is a correlation which _does_ suggest causation. Hence, we might look at release point consistency, velocity, pitch selection, trade history, or nearly any other factor we can get our hands on. (Again, this factor cannot be one that was used to deterine similarity.)\n",
    "\n",
    "## Advantages\n",
    "\n",
    "Retrospetive models can be use to analyze data after it has been collected. Thus, if we already have a lot of data about something, we can look for causation even if we didn't plan to ahead of time or if other methods of causal inference are impossible for ethical or practical reasons.\n",
    "\n",
    "## Disadvantages\n",
    "\n",
    "This is not Randomized Experimental Design (RED). Even with well constructed controls, it is possible that a some co-factor of an apparent causal factor is the real factor. (For example, caffine consumption might look like a causal factor, but if caffine consumption is corelated with cigarette smoking, then this may be only apparent. RED controls for this. In a retrospective model, the researcher must look for it.) \n",
    "\n",
    "Additionally, retrospective models cannot be used to determine effectiveness. Because the control group necessarily does not have the effect condition, there is no way to guage how much a causal factor influences the effect condition. Of course, once a causal hypothesis has been identified, it may be possible by other means to estimate effectiveness. \n",
    "\n",
    "#### Further Reading\n",
    "\n",
    "See Giere, R. _Understanding Scientific Reasoning_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retro:\n",
    "    '''A class for analyzing data for causal relationships with a retrospective model.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    effect_label: str\n",
    "        The label of the column containing the effect condition.\n",
    "    \n",
    "    causal_variables: list-like\n",
    "        a list of columns containing variables to test for causal influence.\n",
    "\n",
    "    match_variables: list-like\n",
    "        a list of columns in data that are used to determine the similarity of two entities.\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, data, effect_label, match_variables, causal_variables):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        effect: DataFrame\n",
    "            The data in which a cause might be found.\n",
    "            \n",
    "        effect_label: str\n",
    "            The label of the column in which we find the effect condition of interest. \n",
    "        '''\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "source": [
    "# Matching\n",
    "\n",
    "From the point of view of implementation, the matching process is probably the most complex portion of the problem. Each normalized datapoint is a vector. We need to match each datapoint in the effect group with a datapoint in the control group, using the distance between the vectors as a similarity metric. The matches must be unique and we want to minimize overall dissimilarity.\n",
    "\n",
    "## More precisely\n",
    "\n",
    "Let the effect group be $X = \\{a, b, c\\}$ and the control group be $Y = \\{w, x, y, z\\}$. We want to pair members of X with members of $Y$ in a way that minimizes the distance between the pairs. The pairing should be unique, so that no member of $Y$ is matched to more than one member of $X$. A complexity emerges: what if $a$ and $b$ are each closer to $x$ than to any other member of $Y$. How can we chose whether to pair $a$ or $b$ with $x$? Let $m$ denote our mapping. We want to minimize the total dissimilarity in the sets. Mean squared distance provides a model for such similarity maximization:\n",
    "$$\n",
    "min \\sum{\n",
    "    \\sqrt{\n",
    "    \\frac{(dist(x,m(x))^2}{n}\n",
    "    }\n",
    "}\n",
    "$$\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}