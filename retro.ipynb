{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Developing retropsective causal inference\n",
    "\n",
    "A retrospective model uses data including entities with and without an effect condition. Entities with the effect condition are  matched to those without it. Then, differences in the frequency of the potential causal factors are investigated for correlation with the effect condition. Because we carefully construct the similar, non-effect group to match the effect group, we control for a wide range cofactors. This is not perfect (see \"Disadvantages\" below), but it's a powerful way to survey a wide range of potential causal factors for an effect.\n",
    "\n",
    "## Benefits of Causal inference\n",
    "\n",
    "Causal inferences allow us to influence outcomes. We don't just want to predict how long we will live, how well kids will do in school, or which patients will die of a heart attack: we want to increase our life spans, help kids learn, and prevent needless deaths. Hence, we need to know not only which variables _predict_ but also which variables _cause_ outcomes. \n",
    "\n",
    "\n",
    "## Example: Pitcher Injury\n",
    "\n",
    "Baseball teams often can't do injury experiments on their players. Practically, they need their pitchers to pitch their best, not pitch in a way that investigates the effect of pitching differently. Ethically, they can't expose their pitchers to risky treatments. Legally, the CBA wouldn't allow it. This is an ideal situation for retrospective analysis. Both baseball teams and players want to reduce player injuries, so they need to figure out which factors influence injury risk.\n",
    "\n",
    "Among the varibales that a team can control are workloads, how often and how much he pitches. Does workload influence injury? A retrospective analysis might provide an answer.\n",
    "\n",
    "**Step one:** we identify pitchers who have a particular serious injury, such as a UCL tear requiring ligament replacement. \n",
    "\n",
    "**Step two:** we idenfity pitchers who did not have that injury. For each pitcher in the the group with the injury (the effect group), we identify a similar pitcher in the uninjured group. Similarity can be determined with many factors, as long as we don't include the factors that we want to analyze for an causal influence; initially, we might use age, weight, height, BMI, team affiliation, velocity, ERA, FIP, and prior injury history. Importantly, we leave out variables that specifically track workload; we also try to include variables which might might predict workload (such as ERA--pitchers with a good ERA are pitch more because it wins games) but which won't directly measure it.\n",
    "\n",
    "**Step three:** we examine any features that we didn't use to determine similarity. Any feature that is more common in the injured group is a candidate causal factor; i.e., this is a correlation which _does_ suggest causation. Hence, we might look at release point consistency, velocity, pitch selection, trade history, or nearly any other factor we can get our hands on. (Again, this factor cannot be one that was used to deterine similarity.) Supposing that we are interested in workload in particular, a number of characterizations of workload can be investigated.\n",
    "\n",
    "## Advantages\n",
    "\n",
    "Retrospetive models can be use to analyze data after it has been collected. Thus, if we already have a lot of data about something, we can look for causation even if we didn't plan to ahead of time or if other methods of causal inference are impossible for ethical or practical reasons.\n",
    "\n",
    "It's also powerful for relatively rare conditions. A long term prospective study (i.e., one that looks for effect conditions to emerge) is impractical for a condition that occurs in a small portion of the population. For example, if only 1 in 5,000 people develop esophageal cancer, you would need over one million subjects in a prospective study to get even modest levels of statistical significance and controlling confounds would be difficult. A retrospective study does not have this problem; if we can find 500 individuals who have esophageal cancer and build a control group of 2000 (finding four matches for each effect group member), we can run a much less resource intensive study.\n",
    "\n",
    "## Disadvantages\n",
    "\n",
    "This is not Randomized Experimental Design (RED). Even with well constructed controls, it is possible that a some co-factor of an apparent causal factor is the real factor. (For example, caffine consumption might look like a causal factor, but if caffine consumption is corelated with cigarette smoking, then this may be only apparent. RED controls for this. In a retrospective model, the researcher must look for it.) FOr this reason, retrospective study is often suggested as a first step toward in designing propspective or RED designs.\n",
    "\n",
    "Additionally, retrospective models cannot be used to determine effectiveness. Because the control group necessarily does not have the effect condition, there is no way to guage how much a causal factor influences the effect condition. Of course, once a causal hypothesis has been identified, it may be possible by other means to estimate effectiveness. Again, it is often seuggested as a first step toward determining the parameters of prospective and retrospective designs.\n",
    "\n",
    "#### Further Reading\n",
    "\n",
    "See Giere, R. _Understanding Scientific Reasoning_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retro:\n",
    "    '''A class for analyzing data for causal relationships with a retrospective model.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    effect_label: str\n",
    "        The label of the column containing the effect condition.\n",
    "    \n",
    "    causal_variables: list-like\n",
    "        a list of columns containing variables to test for causal influence.\n",
    "\n",
    "    match_variables: list-like\n",
    "        a list of columns in data that are used to determine the similarity of two entities.\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, data, effect_label, match_variables, causal_variables):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        effect: DataFrame\n",
    "            The data in which a cause might be found.\n",
    "            \n",
    "        effect_label: str\n",
    "            The label of the column in which we find the effect condition of interest. \n",
    "        '''\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "source": [
    "# Euclidean Matching\n",
    "\n",
    "From the point of view of implementation, the matching process is probably the most complex portion of the problem. Each normalized datapoint is a vector. We need to match each datapoint in the effect group with a datapoint in the control group, using the distance between the vectors as a similarity metric. The matches must be unique and we want to minimize overall dissimilarity.\n",
    "\n",
    "## More precisely\n",
    "\n",
    "Let the effect group be $X = \\{a, b, c\\}$ and the control group be $Y = \\{w, x, y, z\\}$. We want to pair members of X with members of $Y$ in a way that minimizes the distance between the pairs. The pairing should be unique, so that no member of $Y$ is matched to more than one member of $X$. A complexity emerges: what if $a$ and $b$ are each closer to $x$ than to any other member of $Y$. How can we chose whether to pair $a$ or $b$ with $x$? Let $m$ denote our mapping. We want to minimize the total dissimilarity in the sets. Mean squared distance provides a model for such similarity maximization:\n",
    "$$\n",
    "min \\sum{\n",
    "    \\sqrt{\n",
    "    \\frac{(dist(x,m(x))^2}{n}\n",
    "    }\n",
    "}\n",
    "$$\n",
    "\n",
    "# Bucket Matching\n",
    "\n",
    "Altermatively, we might bucket all the continuous variables used to match. If we do so, we could require each individual in the effect group to have a match, i.e., someone whose bucketed data is identical.\n",
    "\n",
    "This sort of process makes it certain that we have exact matches as long as our non-effect group from with to select matches is large cmpared with the effect group. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}